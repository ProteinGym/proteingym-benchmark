vars:
  - params.yaml

  - datasets:
{%- for dataset in datasets %}
    - name: {{ dataset.name }}
      local_path: {{ dataset.local_path }}
{%- endfor %}

  - models:
{%- for model in models %}
    - name: {{ model.name }}
      local_path: {{ model.local_path }}
      local_dockerfile: {{ model.local_dockerfile }}
{%- endfor %}

stages:

  setup:
    cmd:
      - mkdir -p logs ${target.output_dir} ${target.metric_dir}
      - echo "Created local directories" > logs/setup.txt
    outs:
      - logs/setup.txt

  upload_to_s3:
    matrix:
      dataset: ${datasets}
      model: ${models}
    cmd:
      - aws s3 cp ${item.dataset.local_path} s3://${aws.s3_training_data_prefix}/datasets --recursive --exclude "*" --include "*.pgdata"
      - aws s3 cp ${item.model.local_path} s3://${aws.s3_training_data_prefix}/models --recursive --exclude "*" --include "README.md"
      - echo "Upload completed at $(date)" > logs/s3_upload_complete.txt
    deps:
      - logs/setup.txt
      - ${item.dataset.local_path}/
      - ${item.model.local_path}/
    outs:
      - logs/s3_upload_complete.txt:
          cache: true

  deploy_to_ecr:
    matrix:
      model: ${models}
    cmd:
      - aws ecr describe-repositories --repository-names ${item.model.name} --region ${aws.region_name} >/dev/null 2>&1 || aws ecr create-repository --repository-name ${item.model.name} --region ${aws.region_name} >/dev/null
      - aws ecr get-login-password --region ${aws.region_name} | docker login --username AWS --password-stdin ${aws.account_id}.dkr.ecr.${aws.region_name}.amazonaws.com
      - docker buildx build --build-arg GIT_CACHE_BUST=${git.git_cache_bust} --platform linux/amd64,linux/arm64 --secret id=git_auth,src=../git-auth.txt -f ${item.model.local_dockerfile} -t ${aws.account_id}.dkr.ecr.${aws.region_name}.amazonaws.com/${item.model.name}:latest ../../.. --push
      - echo "ECR push completed at $(date)" > logs/ecr_push_complete.txt
      - echo "${aws.account_id}.dkr.ecr.${aws.region_name}.amazonaws.com/${item.model.name}:latest" > logs/image_uri.txt
    deps:
      - logs/setup.txt
      - ${item.model.local_dockerfile}
    outs:
      - logs/ecr_push_complete.txt:
          cache: true
      - logs/image_uri.txt:
          cache: true

  create_training_job:
    matrix:
      dataset: ${datasets}
      model: ${models}

    cmd: >
      uv run proteingym-benchmark sagemaker create-training-job
      --model-name ${item.model.name}
      --region-name ${aws.region_name}
      --sagemaker-role-name ${aws.sagemaker_role_name}
      --ecr-repository-uri ${aws.account_id}.dkr.ecr.${aws.region_name}.amazonaws.com/${item.model.name}
      --s3-training-data-prefix ${aws.s3_training_data_prefix}
      --s3-output-prefix ${aws.s3_output_prefix}
      --instance-type ${aws.instance_type}
      --volume-size ${aws.volume_size}
      --dataset-prefix ${item.dataset.name}
      --model-prefix ${item.model.name}
      > logs/create_job_${item.dataset.name}_${item.model.name}.txt

    deps:
      - ../../../src/proteingym/benchmark/cli/sagemaker.py
      - logs/s3_upload_complete.txt
      - logs/ecr_push_complete.txt
      - logs/image_uri.txt

    outs:
      - logs/create_job_${item.dataset.name}_${item.model.name}.txt:
          cache: true

  monitor_training_job:
    matrix:
      dataset: ${datasets}
      model: ${models}

    cmd: >
      uv run proteingym-benchmark sagemaker monitor-training-job
      --region-name ${aws.region_name}
      --job-name $(cat logs/create_job_${item.dataset.name}_${item.model.name}.txt)
      > logs/monitor_job_${item.dataset.name}_${item.model.name}.txt

    deps:
      - ../../../src/proteingym/benchmark/cli/sagemaker.py
      - logs/create_job_${item.dataset.name}_${item.model.name}.txt

    outs:
     - logs/monitor_job_${item.dataset.name}_${item.model.name}.txt:
          cache: true

  calculate_metric:
    matrix:
      dataset: ${datasets}
      model: ${models}

    cmd:
      - aws s3 cp s3://${aws.s3_output_prefix}/$(cat logs/create_job_${item.dataset.name}_${item.model.name}.txt)/output/model.tar.gz ${target.output_dir}/
      - tar -xzf ${target.output_dir}/model.tar.gz -C ${target.output_dir}/
      - rm ${target.output_dir}/model.tar.gz
      - uv run proteingym-benchmark metric calc --output-path ${target.output_dir}/${item.dataset.name}_${item.model.name}.csv --metric-path ${target.metric_dir}/${item.dataset.name}_${item.model.name}.csv

    deps:
      - logs/monitor_job_${item.dataset.name}_${item.model.name}.txt
    outs:
      - ${target.metric_dir}/${item.dataset.name}_${item.model.name}.csv:
          cache: true