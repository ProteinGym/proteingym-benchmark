vars:
  - default.yaml
  - datasets.json
  - models.json

stages:

  setup:
    cmd:
      - mkdir -p logs ${output.prediction} ${output.metric}
      - echo "Created local directories" > logs/setup.txt
    outs:
      - logs/setup.txt

  create_training_job:
    matrix:
      dataset: ${datasets}
      model: ${models}

    cmd:
      - >-
        MODEL=$(python3 -c "import sys,re; model=dict(re.findall(r'--(\w+)\s+(\S+)', sys.argv[1])); print(model.get('input_filename', model.get('image', '')))" "${item.model}") &&
        if [[ "$MODEL" == /* ]]; then
          echo "Building image from local path: $MODEL"
          docker build \
            -f $(dirname "$MODEL")/Dockerfile \
            -t ${item.model.name}:latest \
            $(dirname "$MODEL");
        else
          echo "Pulling image from registry: $MODEL"
          docker pull "$MODEL" &&
          docker tag "$MODEL" ${item.model.name}:latest;
        fi
      - >-
        if [[ "$MODEL" == /* ]]; then
          docker run --rm \
            -v $(realpath ${item.dataset.input_filename}):/$(basename ${item.dataset.input_filename}) \
            -v $(realpath "$MODEL"):/$(basename "$MODEL") \
            -v $(realpath ${output.prediction}):/opt/program/output \
            ${item.model.name}:latest \
            train \
              --dataset-file /$(basename ${item.dataset.input_filename}) \
              --model-card-file /$(basename "$MODEL");
        else
          docker run --rm \
            -v $(realpath ${item.dataset.input_filename}):/$(basename ${item.dataset.input_filename}) \
            -v $(realpath ${output.prediction}):/opt/program/output \
            ${item.model.name}:latest \
            train \
              --dataset-file /$(basename ${item.dataset.input_filename});
        fi
      - docker image prune -a -f
    deps:
      - logs/setup.txt
      - ${item.dataset.input_filename}
    outs:
      - ${output.prediction}/${item.dataset.name}_${item.model.name}.csv:
          cache: true

  calculate_metric:
    matrix:
      dataset: ${datasets}
      model: ${models}

    cmd:      
      - >- 
        METRICS=$(python -c "import yaml; data = yaml.safe_load(open('default.yaml')); print(' '.join(data['metrics']))") &&
        python $(dvc root)/scripts/metric.py
        --prediction-path ${output.prediction}/${item.dataset.name}_${item.model.name}.csv
        --metric-path ${output.metric}/${item.dataset.name}_${item.model.name}.json
        --selected-metrics $METRICS

    deps:
      - ${output.prediction}/${item.dataset.name}_${item.model.name}.csv
    metrics:
      - ${output.metric}/${item.dataset.name}_${item.model.name}.json:
          cache: false
